# Author: Russell Williams
# Email: russell.d.williams@gmail.com

# Generates heroic couplets using sonnet.py, rates them using a model
# generated by rate.py, and posts the best ones to Twitter.

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.


import sonnet as snt
from tensorflow.contrib import skflow
import model
import numpy as np
import logging
import tweepy
from secrets import *
import datetime
import time
import pickle

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

logging.info("Loading humanity model...")
hum_classifier = skflow.TensorFlowEstimator.restore("models/human_classifier_20160510")
logging.info("Done.")
logging.info("Loading interest model...")
int_classifier = skflow.TensorFlowEstimator.restore("models/interest_classifier_20160510")
logging.info("Done.")

HUMAN_REV_MAPPING = ['<UNK>', 'low', 'moderate', 'high']
INTEREST_REV_MAPPING = ['<UNK>', 'low', 'moderate', 'high']

vocab = snt.Vocab()
sw = snt.SonnetWriter(vocab)
sw.load_templates("line_templates.csv")

vocab.add_random_collections(2)
couplets = snt.HeroicCouplets(12)

sw.new_poem(couplets)

seqs = [model.convert_to_sequence(section) for section in couplets.sections]
X = np.array(list(model.transform(seqs)))


def sum_ratings(probs):
    return sum([prob * rating for prob, rating in zip(probs, range(4))])


hum_ratings = [sum_ratings(probs) * 3 for probs in hum_classifier.predict_proba(X)]
int_ratings = [sum_ratings(probs) * 3 for probs in int_classifier.predict_proba(X)]

for section, hum_rat, int_rat in zip(couplets.sections, hum_ratings, int_ratings):
    section.human = hum_rat
    section.interesting = int_rat

timestamp = datetime.datetime.now()
filename = "unrated_couplet_batch_{}.pickle".format(timestamp.strftime("%Y%m%d-%H%H"))
with open(filename, "wb") as f:
    pickle.dump(couplets, f)

couplets.sections.sort(key=lambda x: x.human * x.interesting)
couplets.sections.reverse()

auth = tweepy.OAuthHandler(C_KEY, C_SECRET)
auth.set_access_token(A_TOKEN, A_TOKEN_SECRET)
api = tweepy.API(auth)

NUM_TO_TWEET = 3

for couplet in couplets.sections[:NUM_TO_TWEET]:
    api.update_status(couplet.text)
    time.sleep(30)
