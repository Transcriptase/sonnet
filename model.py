# Author: Russell Williams
# Email: russell.d.williams@gmail.com
# Copyright 2016

# Trains an RNN to rate sonnets generated by sonnet.py

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.

import pickle
from tensorflow.contrib import skflow
import numpy as np
import tensorflow as tf
import sklearn
import glob
import datetime

def convert_to_sequence(section):
    sequence = []
    for template, line in zip(section.template_list, section.lines):
        sequence.append(template.raw_text)
        for choice in line.choices:
            sequence.append(choice)
    return sequence

def bin_rating(rating, low_break, high_break):
    if rating < low_break:
        return "low"
    elif rating < high_break:
        return "moderate"
    else:
        return "high"



class ModelConfig(object):
    def __init__(self):
        self.hum_cv = skflow.preprocessing.categorical_vocabulary.CategoricalVocabulary()
        self.int_cv = skflow.preprocessing.categorical_vocabulary.CategoricalVocabulary()
        self.transform_matrix = skflow.preprocessing.categorical_vocabulary.CategoricalVocabulary()
        self.n_words = 0
        self.max_seq_len = 0
        self.embedding_size = 50

    def initialize_transform_matrix(self, seqs):
        for seq in seqs:
            for item in seq:
                self.transform_matrix.add(item)
        self.transform_matrix.freeze()
        self.n_words = len(self.transform_matrix._mapping)
        self.max_seq_len = max([len(seq) for seq in seqs])

    def initialize_rank_mapping(self, cv, binned_ratings):
        for row in binned_ratings:
            cv.add(row)
        cv.freeze()

    def prepare_rating_cats(self, cv, binned_ratings):
        def transform_cat(cat):
            for rating in cat:
                yield(cv.get(rating))
        y = np.array(list(transform_cat(binned_ratings)))
        return y

    def transform_seqs(self, seqs):
        def transformer():
            for seq in seqs:
                choice_ids = np.zeros(self.max_seq_len, np.int64)
                for index, choice in enumerate(seq):
                    if index >= self.max_seq_len:
                        break
                    choice_ids[index] = self.transform_matrix.get(choice)
                yield (choice_ids)
        x = np.array(list(transformer()))
        return x

if __name__ == "__main__":
    rated_batches = glob.glob("rated/*.pickle")
    rated_sonnets = []

    for batch in rated_batches:
        with open(batch, "r") as f:
            rated_sonnets.extend(pickle.load(f))

    seqs = [convert_to_sequence(section) for sonnet in rated_sonnets for section in sonnet.sections]
    human_score_cat = [bin_rating(section.human, 4, 6) for sonnet in rated_sonnets for section in sonnet.sections]
    interest_score_cat = [bin_rating(section.interesting, 4, 7) for sonnet in rated_sonnets for section in
                          sonnet.sections]
    offense_score_cat = [bin_rating(section.offensive, 1, 4) for sonnet in rated_sonnets for section in sonnet.sections]

    config = ModelConfig()

    config.initialize_transform_matrix(seqs)
    config.initialize_rank_mapping(config.int_cv, interest_score_cat)
    config.initialize_rank_mapping(config.hum_cv, human_score_cat)

    x = config.transform_seqs(seqs)
    int_y = config.prepare_rating_cats(config.int_cv, interest_score_cat)
    hum_y = config.prepare_rating_cats(config.hum_cv, human_score_cat)

    datestamp = datetime.datetime.today().strftime("%Y%m%d")
    with open("models/model_config_{}.pickle".format(datestamp), "wb") as f:
        pickle.dump(config, f)

    x_train, x_test, int_y_train, int_y_test = sklearn.cross_validation.train_test_split(x, int_y,
                                                                                         test_size=0.2, random_state=1)


    def rnn_model(x, y):
        """Recurrent neural network to predict from sequence of templates/choices to a class"""
        # Create embedding matrix of size [n_words, EMBEDDING_SIZE] then maps word indexes of the sequence
        # into [batch_size, sequence_length, EMBEDDING_SIZE]
        choice_vectors = skflow.ops.categorical_variable(x, n_classes=config.n_words,
                                                         embedding_size=config.embedding_size,
                                                         name="choices")
        # Split into list of embedding per choice, removing seq length dim
        # Result is a list of tensors [batch_size, EMBEDDING_SIZE]
        choice_list = skflow.ops.split_squeeze(1, config.max_seq_len, choice_vectors)
        # Create Gated Recurrent Unit cell with hidden size EMBEDDING_SIZE
        cell = tf.nn.rnn_cell.GRUCell(config.embedding_size)
        cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=0.5)
        cells = tf.nn.rnn_cell.MultiRNNCell([cell] * 3)
        # Create the network to length MAX_SEQUENCE_LENGTH and pass choice_list to each unit
        _, encoding = tf.nn.rnn(cells, choice_list, dtype=tf.float32)
        # Use encoding of last step and pass it a features for logistic regression
        # over output classes
        return skflow.models.logistic_regression(encoding, y)

    classifier = skflow.TensorFlowEstimator(model_fn=rnn_model, n_classes=len(config.int_cv._mapping), steps=1000,
                                            optimizer="Adam", learning_rate=0.01, continue_training=True)

    classifier.fit(x_train, int_y_train, logdir='/tmp/snt_model')
    score = sklearn.metrics.accuracy_score(int_y_test, classifier.predict(x_test))
    print("Accuracy: {0:f}".format(score))

    classifier.save("models/int_classifier_{}".format(datestamp))

    x_train, x_test, hum_y_train, hum_y_test = sklearn.cross_validation.train_test_split(x, hum_y,
                                                                                         test_size=0.2, random_state=1)

    classifier = skflow.TensorFlowEstimator(model_fn=rnn_model, n_classes=4, steps=1000, optimizer="Adam",
                                            learning_rate=0.01, continue_training=True)

    classifier.fit(x_train, hum_y_train, logdir='/tmp/snt_model')
    score = sklearn.metrics.accuracy_score(hum_y_test, classifier.predict(x_test))
    print("Accuracy: {0:f}".format(score))

    classifier.save("models/hum_classifier_{}".format(datestamp))
